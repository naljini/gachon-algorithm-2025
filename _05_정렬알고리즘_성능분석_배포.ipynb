{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naljini/gachon-algorithm-2025/blob/main/_05_%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_%EC%84%B1%EB%8A%A5%EB%B6%84%EC%84%9D_%EB%B0%B0%ED%8F%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ë¶„ì„**"
      ],
      "metadata": {
        "id": "HAXUGc0BrC7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "syv67br4rFfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(ì½”ë©ì—ì„œ)í•œê¸€ í°íŠ¸ ì§€ì •í•˜ëŠ” ë°©ë²•**"
      ],
      "metadata": {
        "id": "Uzqyux7fJbNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "# ì½”ë©ì—ì„œ ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¨ í›„  ë°˜ë“œì‹œ ì½”ë© ë©”ë‰´: \"ëŸ°íƒ€ì„>ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘\" í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "collapsed": true,
        "id": "A_oQRimiJPhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumGothic')       # (ì½”ë©)í•œê¸€ í°íŠ¸"
      ],
      "metadata": {
        "id": "xTBXzrFAJ8Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vdh2d1iCKKI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸**\n",
        "\n",
        "- ì•„ë˜ ì¡°ê±´ì— ëŒ€í•´ ì •ë ¬ì´ ì˜ ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸°\n",
        "    1. **ì •ìˆ˜ ë°ì´í„° ì •ë ¬** : ë‚´ë¶€ ì •ë ¬í•¨ìˆ˜ì™€ ë°ì´í„° ë¹„êµ(ë‚´ë¶€í•¨ìˆ˜ vs ì •ë ¬í•¨ìˆ˜)\n",
        "    2. **[] ë¹ˆ ë°ì´í„°** ì •ë ¬\n",
        "    3. **ìŒìˆ˜ ë°ì´í„°** ì •ë ¬\n",
        "    4. **np.array ë°ì´í„°** ì •ë ¬\n",
        "    5. **ì´ë¯¸ ì •ë ¬ì´ ëœ ë°ì´í„°** ì •ë ¬\n",
        "    6. **ì—­ìˆœ ì •ë ¬ì´ ëœ ë°ì´í„°** ì •ë ¬\n",
        "    7. **í° ë°ì´í„°** ì •ë ¬"
      ],
      "metadata": {
        "id": "KiupI2zMrOE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **@í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ ë§Œë“¤ê¸°**: test_sort()\n",
        "\n",
        "- í•¨ìˆ˜ëª…: test_sort(ì •ë ¬í•¨ìˆ˜ëª…, ì •ë ¬í•  ë°ì´í„°, ë°ì´í„° ì„¤ëª…)"
      ],
      "metadata": {
        "id": "fzsTVBRrKxtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
        "# -------------------------------\n",
        "\n",
        "def test_sort(sort_func, data, label=\"\", sort_show=False):\n",
        "    '''\n",
        "    sort_func : ì •ë ¬í•¨ìˆ˜ëª…,\n",
        "    data : ì •ë ¬í•  ë°ì´í„°,\n",
        "    label : ë°ì´í„° ì„¤ëª…\n",
        "    '''\n",
        "\n",
        "    # ì›ë³¸ ë°ì´í„° ë³µì‚¬\n",
        "    original = np.copy(data) if isinstance(data, np.ndarray) else list(data)\n",
        "    test_data = np.copy(data) if isinstance(data, np.ndarray) else list(data)\n",
        "\n",
        "    # ì •ë ¬ ìˆ˜í–‰\n",
        "    test_data = sort_func(test_data, len(test_data))\n",
        "\n",
        "    # ê¸°ëŒ€ ê²°ê³¼ ê³„ì‚°\n",
        "    expected = np.sort(original) if isinstance(data, np.ndarray) else sorted(original)\n",
        "\n",
        "    # ë¹„êµ ê²°ê³¼ ì¶œë ¥\n",
        "    passed = np.array_equal(test_data, expected) if isinstance(data, np.ndarray) else test_data == expected\n",
        "    print(f\"[{sort_func.__name__}] {label}: {'âœ… PASS' if passed else 'âŒ FAIL'}\")\n",
        "    if not passed:\n",
        "        print(\"Expected:\", expected)\n",
        "        print(\"Got     :\", test_data)\n",
        "\n",
        "    # ì •ë ¬ ì „, í›„ ì¶œë ¥\n",
        "    if sort_show:\n",
        "        print(\" Before sorting: \", end = '')\n",
        "        print(data)\n",
        "        print(\" After sorting : \", end = '')\n",
        "        print(test_data)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SdA7iyaD_0g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bubble Sort**"
      ],
      "metadata": {
        "id": "5b4maBOM_uNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bubble_sort(A, n):  # swap ë°©ì‹\n",
        "\n",
        "\n",
        "    return A\n"
      ],
      "metadata": {
        "id": "iYbTAM3lrOYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Bubble Sort ì •ë ¬í•˜ê¸°"
      ],
      "metadata": {
        "id": "wyTWQu0SQEN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sort(bubble_sort, [11, 1, 51, 1, 5, 3], \"1.List with duplicates\", False)\n",
        "test_sort(bubble_sort, [], \"2.Empty list\")\n",
        "test_sort(bubble_sort, [1, 1, -5, 6], \"3.List with negative numbers\")\n",
        "test_sort(bubble_sort, np.array([11, -4, 20, 15, 13.5, -20]), \"4.Numpy array with floats\")\n",
        "test_sort(bubble_sort, np.array(range(50)), \"5.Already sorted array\")\n",
        "test_sort(bubble_sort, np.arange(50, 0, -5), \"6.Reversed array\")\n",
        "test_sort(bubble_sort, np.random.randint(-5000, 5000, size=1000), \"7/Large random array\")"
      ],
      "metadata": {
        "id": "6hfI6HklNyZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Selection Sort**"
      ],
      "metadata": {
        "id": "sp01aJR3K8oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selection_sort í•¨ìˆ˜\n",
        "def selection_sort(A, n):    # ìµœëŒ€ê°’ ì°¾ê¸° ë°©ì‹\n",
        "\n",
        "\n",
        "\n",
        "    return A"
      ],
      "metadata": {
        "id": "84tA1UyFK9gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Selection Sort ì •ë ¬í•˜ê¸°"
      ],
      "metadata": {
        "id": "fWZATfnyoCKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selection_sort í…ŒìŠ¤íŠ¸\n",
        "test_sort(selection_sort, [11, 1, 51, 1, 5, 3], \"List with duplicates\")\n",
        "test_sort(selection_sort, [], \"Empty list\")\n",
        "test_sort(selection_sort, [1, 1, -5, 6], \"List with negative numbers\")\n",
        "test_sort(selection_sort, np.array([11, -4, 20, 15, 13.5, -20]), \"Numpy array with floats\")\n",
        "test_sort(selection_sort, np.array(range(50)), \"Already sorted array\")\n",
        "test_sort(selection_sort, np.arange(50, 0, -5), \"Reversed array\")\n",
        "test_sort(selection_sort, np.random.randint(-5000, 5000, size=1000), \"Large random array\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tZllpPxhMSYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "troBFmfYOWYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Insertion Sort**"
      ],
      "metadata": {
        "id": "m4Wz-7lz_1Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insertion_sort í•¨ìˆ˜\n",
        "def insertion_sort(A, n):\n",
        "\n",
        "\n",
        "\n",
        "    return A"
      ],
      "metadata": {
        "id": "YMY5uGNPNTQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Insertion Sort ì •ë ¬í•˜ê¸°"
      ],
      "metadata": {
        "id": "aF4DMbEpoQCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insertion_sort í…ŒìŠ¤íŠ¸\n",
        "test_sort(insertion_sort, [11, 1, 51, 1, 5, 3], \"List with duplicates\")\n",
        "test_sort(insertion_sort, [], \"Empty list\")\n",
        "test_sort(insertion_sort, [1, 1, -5, 6], \"List with negative numbers\")\n",
        "test_sort(insertion_sort, np.array([11, -4, 20, 15, 13.5, -20]), \"Numpy array with floats\")\n",
        "test_sort(insertion_sort, np.array(range(50)), \"Already sorted array\")\n",
        "test_sort(insertion_sort, np.arange(50, 0, -5), \"Reversed array\")\n",
        "# test_sort(insertion_sort, np.random.randint(-5000, 5000, size=1000), \"Large random array\")"
      ],
      "metadata": {
        "id": "MdOpAe5aLGMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5T6UBixpRDlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **@í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ìµœì í™”**\n",
        "- ë¦¬ìŠ¤íŠ¸ì™€ ë°˜ë³µë¬¸ì„ ì´ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ ì •ë ¬í•¨ìˆ˜ë¥¼ ë°˜ë³µí•´ì„œ í˜¸ì¶œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ ì½”ë“œë¥¼ êµ¬í˜„í•˜ì‹œì˜¤.\n",
        "- ì •ë ¬í•¨ìˆ˜ ëª©ë¡ **sort_algorithms = [bubble_sort, selection_sort, insertion_sort]**"
      ],
      "metadata": {
        "id": "EqwOlkiDQXDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
        "# -------------------------------\n",
        "test_cases = [\n",
        "    ([11, 1, 51, 1, 5, 3], \"1.List with duplicates\"),\n",
        "    ([], \"2.Empty list\"),\n",
        "    ([1, 1, -5, 6], \"3.List with negative numbers\"),\n",
        "    (np.array([11, -4, 20, 15, 13.5, -20]), \"4.Numpy array with floats\"),\n",
        "    (np.array(range(50)), \"5.Already sorted array\"),\n",
        "    (np.arange(50, 0, -5), \"6.Reversed array\"),\n",
        "    (np.random.randint(-5000, 5000, size=1000), \"7.Large random array\"),\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# ì•Œê³ ë¦¬ì¦˜ ë°˜ë³µ í…ŒìŠ¤íŠ¸\n",
        "# -------------------------------\n",
        "sort_algorithms = [bubble_sort, selection_sort, insertion_sort]\n",
        "\n",
        "for sort_func in sort_algorithms:\n",
        "    print(f\"\\nğŸ” Testing: {sort_func.__name__}\")\n",
        "    for data, label in test_cases:\n",
        "        test_sort(sort_func, data, label)\n"
      ],
      "metadata": {
        "id": "0RSf3jJLRLGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "K-pPDPh2NQqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merge Sort**"
      ],
      "metadata": {
        "id": "QeJLPwgvPpg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Merge Sort ì •ë ¬í•˜ê¸°\n",
        "- [ì£¼ì˜] ì…ë ¥ì´ np.arrayë©´ listë¡œ ë³€í™˜í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "kdwTOpVio0fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(left, right):\n",
        "    # print('->left:', list(left), 'right:', list(right))\n",
        "    merged = []\n",
        "    l_idx, r_idx = 0, 0\n",
        "\n",
        "    while l_idx < len(left) and r_idx < len(right):\n",
        "        if left[l_idx] < right[r_idx]:\n",
        "            merged.append(left[l_idx])\n",
        "            l_idx += 1\n",
        "        else:\n",
        "            merged.append(right[r_idx])\n",
        "            r_idx += 1\n",
        "\n",
        "    merged += left[l_idx:]\n",
        "    merged += right[r_idx:]\n",
        "    return merged\n",
        "\n",
        "def merge_sort(A, n):\n",
        "    # ì…ë ¥ì´ np.arrayë©´ listë¡œ ë³€í™˜\n",
        "    if isinstance(A, np.ndarray):\n",
        "        A = A.tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "arr = np.array([11, -4, 20, 15, 13.5, -20])\n",
        "print(\"ì •ë ¬ ì´ì „: \", arr)\n",
        "print(\"ì •ë ¬ ì´í›„: \", merge_sort(arr, len(arr)) )\n"
      ],
      "metadata": {
        "id": "l39WcSEvPtn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Quick Sort**"
      ],
      "metadata": {
        "id": "szRnQte6P8C2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Quick Sort ì •ë ¬í•˜ê¸°"
      ],
      "metadata": {
        "id": "XUr77ysgpGFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  quick_sort í•¨ìˆ˜\n",
        "def quick_sort(A, n):\n",
        "\n",
        "\n",
        "\n",
        "    # ì¬ê·€ì ìœ¼ë¡œ ì •ë ¬í•œ ê²°ê³¼ë¥¼ ê²°í•©\n",
        "    return quick_sort(left, len(left)) + [pivot] + quick_sort(right, len(right))\n",
        "\n",
        "\n",
        "# ì˜ˆì‹œ ì‚¬ìš©\n",
        "arr = [24, 9, 29, 14, 19, 27]\n",
        "print(\"ì •ë ¬ ì´ì „: \", arr)\n",
        "print(\"ì •ë ¬ ì´í›„: \", quick_sort(arr, len(arr)) )"
      ],
      "metadata": {
        "id": "S1ODqFBDQAHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Heap Sort**"
      ],
      "metadata": {
        "id": "Vl9qQuC4QJSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** Heap Sort ì •ì˜í•˜ê¸°"
      ],
      "metadata": {
        "id": "7mIz8LOUpJT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  heap_sort í•¨ìˆ˜\n",
        "def heapify(arr, n, i):\n",
        "    largest = i          # ë£¨íŠ¸ ë…¸ë“œ\n",
        "    left = 2 * i + 1     # ì™¼ìª½ ìì‹\n",
        "    right = 2 * i + 2    # ì˜¤ë¥¸ìª½ ìì‹\n",
        "\n",
        "    # ì™¼ìª½ ìì‹ì´ ë£¨íŠ¸ë³´ë‹¤ í¬ë©´\n",
        "    if left < n and arr[left] > arr[largest]:\n",
        "        largest = left\n",
        "\n",
        "    # ì˜¤ë¥¸ìª½ ìì‹ì´ í˜„ì¬ê¹Œì§€ ê°€ì¥ í° ë…¸ë“œë³´ë‹¤ í¬ë©´\n",
        "    if right < n and arr[right] > arr[largest]:\n",
        "        largest = right\n",
        "\n",
        "    # largestê°€ ë£¨íŠ¸ê°€ ì•„ë‹ˆë¼ë©´, swap í›„ ì¬ê·€ í˜¸ì¶œ\n",
        "    if largest != i:\n",
        "        arr[i], arr[largest] = arr[largest], arr[i]\n",
        "        # print_tree(arr, n, largest    # íŠ¸ë¦¬ ì‹œê°í™”: ë°©ë²•1\n",
        "        # visualize_heap(arr, largest)    # íŠ¸ë¦¬ ì‹œê°í™”: ë°©ë²•2\n",
        "        heapify(arr, n, largest)\n",
        "\n",
        "    # print(arr)\n",
        "\n",
        "\n",
        "def heap_sort(A, n):\n",
        "    # 1. ìµœëŒ€ í™(Max Heap) êµ¬ì„±\n",
        "\n",
        "\n",
        "    # 2. í•˜ë‚˜ì”© ë£¨íŠ¸(ìµœëŒ“ê°’)ë¥¼ êº¼ë‚´ì„œ ì •ë ¬ ìœ„ì¹˜ë¡œ ì´ë™\n",
        "\n",
        "\n",
        "    return A\n",
        "\n",
        "# ì˜ˆì‹œ ì‚¬ìš©\n",
        "arr = [81, 89, 9, 11, 14, 76, 54, 22]\n",
        "print(\"ì •ë ¬ ì´ì „: \", arr)\n",
        "print(\"ì •ë ¬ ì´í›„: \", heap_sort(arr, len(arr)) )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mepT4Sc1WnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- íŠ¸ë¦¬ ì‹œê°í™”"
      ],
      "metadata": {
        "id": "wtxKuPePve4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°©ë²•1 : ë“¤ì—¬ì“°ê¸°ë¡œ íŠ¸ë¦¬ ì‹œê°í™”\n",
        "def print_tree(arr, n, current_node=-1):\n",
        "    \"\"\"ë°°ì—´ì„ ë“¤ì—¬ì“°ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë¦¬ í˜•íƒœë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
        "    if n == 0:\n",
        "        print(\"(ë¹ˆ í™)\")\n",
        "        return\n",
        "\n",
        "    def print_level(arr, n, index, level, indent, current):\n",
        "        if index < n:\n",
        "            print(f\"{indent}{'[' if index == current else ''}{arr[index]}{']' if index == current else ''}\")\n",
        "            left_child = 2 * index + 1\n",
        "            right_child = 2 * index + 2\n",
        "            next_indent = indent + \"--\"\n",
        "            print_level(arr, n, left_child, level + 1, next_indent, current)\n",
        "            print_level(arr, n, right_child, level + 1, next_indent, current)\n",
        "\n",
        "    print(\"í™ êµ¬ì¡°:\")\n",
        "    print_level(arr, n, 0, 0, \"\", current_node)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "sorted_arr = heap_sort(arr, len(arr))\n",
        "print_tree(sorted_arr, len(sorted_arr))"
      ],
      "metadata": {
        "id": "lE1rV0orB4RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°©ë²•2 : networks ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ íŠ¸ë¦¬ ì‹œê°í™”\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_heap(arr, current_node=-1):\n",
        "    \"\"\"networkxë¥¼ ì´ìš©í•˜ì—¬ í™(íŠ¸ë¦¬) êµ¬ì¡°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
        "    n = len(arr)\n",
        "\n",
        "    if n == 0:\n",
        "        print(\"(ë¹ˆ í™)\")\n",
        "        return\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # ë…¸ë“œ ì¶”ê°€ (ê°’ì€ labelë¡œ, ì¸ë±ìŠ¤ë¥¼ node idë¡œ)\n",
        "    for i in range(n):\n",
        "        label = f\"[{arr[i]}]\" if i == current_node else str(arr[i])\n",
        "        G.add_node(i, label=label)\n",
        "\n",
        "    # ê°„ì„  ì¶”ê°€ (ì´ì§„ íŠ¸ë¦¬ êµ¬ì¡°)\n",
        "    for i in range(n):\n",
        "        left = 2 * i + 1\n",
        "        right = 2 * i + 2\n",
        "        if left < n:\n",
        "            G.add_edge(i, left)\n",
        "        if right < n:\n",
        "            G.add_edge(i, right)\n",
        "\n",
        "    # ë ˆì´ì•„ì›ƒ ì •ì˜ (tree layoutì²˜ëŸ¼ ë³´ì´ê²Œ)\n",
        "    def hierarchy_pos(G, root=0, width=1., vert_gap=0.2, vert_loc=0, xcenter=0.5, pos=None, parent=None):\n",
        "        \"\"\"íŠ¸ë¦¬ êµ¬ì¡°ì˜ ê³„ì¸µì  ìœ„ì¹˜ ê³„ì‚° í•¨ìˆ˜\"\"\"\n",
        "        if pos is None:\n",
        "            pos = {root: (xcenter, vert_loc)}\n",
        "        else:\n",
        "            pos[root] = (xcenter, vert_loc)\n",
        "        children = list(G.successors(root))\n",
        "        if len(children) != 0:\n",
        "            dx = width / 2\n",
        "            nextx = xcenter - width/2 - dx/2\n",
        "            for child in children:\n",
        "                nextx += dx\n",
        "                pos = hierarchy_pos(G, child, width=dx, vert_gap=vert_gap,\n",
        "                                    vert_loc=vert_loc - vert_gap, xcenter=nextx, pos=pos, parent=root)\n",
        "        return pos\n",
        "\n",
        "    pos = hierarchy_pos(G)\n",
        "\n",
        "    labels = nx.get_node_attributes(G, 'label')\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    nx.draw(G, pos, with_labels=False, arrows=False, node_size=1000, node_color='skyblue')\n",
        "    nx.draw_networkx_labels(G, pos, labels, font_size=10, font_weight='bold')\n",
        "    plt.title(\"Heap Tree Visualization\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "sorted_arr = heap_sort(arr, len(arr))\n",
        "visualize_heap(sorted_arr)\n"
      ],
      "metadata": {
        "id": "ccMJQEXXwKRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Shell Sort**"
      ],
      "metadata": {
        "id": "elwz8gE6WsLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shell_sort í•¨ìˆ˜\n",
        "def shell_sort(A, n):\n",
        "    gap = n // 2  # ì´ˆê¸° ê°„ê²© ì„¤ì •\n",
        "\n",
        "    # ê°„ê²©ì„ ì¤„ì—¬ê°€ë©´ì„œ ë°˜ë³µ\n",
        "\n",
        "\n",
        "    return A\n"
      ],
      "metadata": {
        "id": "aZJgdL0tWskt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]**  ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸ í•˜ê¸°\n",
        "- ì•ì—ì„œ ì‘ì„±í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ sort_algorithms ë¦¬ìŠ¤íŠ¸, test_sortí•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬\n",
        "- merge_sort, quick_sort, heap_sort, shell_sort ì •ë ¬ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸ í•´ë³´ì„¸ìš”."
      ],
      "metadata": {
        "id": "V5KZOtTNxbsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# ì•Œê³ ë¦¬ì¦˜ ë°˜ë³µ í…ŒìŠ¤íŠ¸\n",
        "# -------------------------------\n",
        "sort_algorithms = [merge_sort, quick_sort, heap_sort, shell_sort]\n",
        "\n",
        "for sort_func in sort_algorithms:\n",
        "    print(f\"\\nğŸ” Testing: {sort_func.__name__}\")\n",
        "    for data, label in test_cases:\n",
        "        test_sort(sort_func, data, label)"
      ],
      "metadata": {
        "id": "CbUl9KU-XL-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UQUABtndL5yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ë¹„êµ(ì‹œê°„ ì¸¡ì •)**"
      ],
      "metadata": {
        "id": "nxvGPVQBODiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **í•œ ê°œì˜ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ì¸¡ì •** (ìˆ«ì ë°ì´í„°)"
      ],
      "metadata": {
        "id": "UpGd6JO1L-FE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ë°ì´í„° í¬ê¸°(Size)ë³„ ì •ë ¬ ì‹œê°„ ì¸¡ì •**(â¡ï¸1ì°¨ì‹œ ì‹¤ìŠµì½”ë“œ ì°¸ê³ ) <br>\n",
        "- **ë°ì´í„°** : random.randint(0, 10000)\n",
        "- **ì‹œê°„ì¸¡ì • í•¨ìˆ˜** : measure_time(ì •ë ¬ ì•Œê³ ë¦¬ì¦˜, ë°ì´í„° í¬ê¸°)\n",
        "- **í¬ê¸°ë³„ ë°ì´í„°**   : sizes = [100, 500, 1000, 5000]\n",
        "- **ì •ë ¬ ì•Œê³ ë¦¬ì¦˜** : sort_funcs = bubble_sort\n",
        "- **ì•Œê³ ë¦¬ì¦˜ë³„ ì¸¡ì • ì‹œê°„ ì €ì¥** :  bubble_times = []"
      ],
      "metadata": {
        "id": "uD6s9Wp1MajR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ì˜ ì‹œê°„ ì„±ëŠ¥ ë¹„êµ\n",
        "import time\n",
        "import random\n",
        "\n",
        "def measure_time(sort_func, size):\n",
        "    arr = [random.randint(0, 10000) for _ in range(size)]\n",
        "    start = time.time()  # ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
        "    sort_func(arr, len(arr))\n",
        "    end = time.time()    # ì‹œê°„ ì¸¡ì • ì¢…ë£Œ\n",
        "    return end - start\n",
        "\n",
        "# ë°ì´í„° í¬ê¸°\n",
        "sizes = [100, 500, 1000, 5000]\n",
        "for size in sizes:\n",
        "    print(f\"Size {size}: Bubble Sort = {measure_time(bubble_sort, size):.6f} sec\")"
      ],
      "metadata": {
        "id": "1trXc4SzL1dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ê·¸ë˜í”„ë¡œ ì‹œê°í™”"
      ],
      "metadata": {
        "id": "AyGuGaw6MYUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê·¸ë˜í”„ë¡œ í‘œí˜„\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def measure_time(sort_func, sizes):\n",
        "    times = []\n",
        "    for size in sizes:\n",
        "        arr = [random.randint(0, 10000) for _ in range(size)]\n",
        "        start = time.time()             # ì‹œì‘ ì‹œê°„ ì¸¡ì •\n",
        "        sort_func(arr, len(arr))\n",
        "        end = time.time()               # ì¢…ë£Œ ì‹œê°„ ì¸¡ì •\n",
        "        times.append(end - start)\n",
        "    return times\n",
        "\n",
        "# ë°ì´í„° í¬ê¸°\n",
        "sizes = [100, 500, 1000, 5000]\n",
        "\n",
        "# ì‹œê°„ ì¸¡ì •í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë‹´ê¸°\n",
        "bubble_times = measure_time(bubble_sort, sizes)\n",
        "\n",
        "# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.plot(sizes, bubble_times, label=\"Bubble Sort\", marker='o')\n",
        "plt.xlabel(\"Input Size\")\n",
        "plt.ylabel(\"Execution Time (seconds)\")\n",
        "plt.legend()\n",
        "plt.title(\"Algorithm Complexity Analysis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DD00c_vqMTeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Dq0dTJVGA8gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì—¬ëŸ¬ ê°œ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ**\n",
        "- ë°ì´í„° í¬ê¸°   : sizes = [100, 500, 1000, 5000]\n",
        "- ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ : sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "- ì•Œê³ ë¦¬ì¦˜ë³„ ì¸¡ì • ì‹œê°„ ì €ì¥: func_times = [[] for _ in sort_funcs]  # ë™ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n"
      ],
      "metadata": {
        "id": "QjeUTZpdLZYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì½”ë“œ ì‘ì„±\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ì‹¤í–‰ ì‹œê°„ ì¸¡ì • í•¨ìˆ˜\n",
        "def measure_time(sort_funcs, arr):\n",
        "    times = []\n",
        "    for sort_func in sort_funcs:\n",
        "        arr_copy = arr[:]  # ì›ë³¸ ë°°ì—´ ë³´í˜¸ (ì •ë ¬ í›„ ë°°ì—´ì´ ë°”ë€Œë¯€ë¡œ ë³µì‚¬)\n",
        "        start = time.time()\n",
        "        sort_func(arr_copy, len(arr_copy))\n",
        "        end = time.time()\n",
        "        times.append(end - start)\n",
        "    return times\n",
        "\n",
        "\n",
        "# ë²¤ì¹˜ë§ˆí¬ í•¨ìˆ˜\n",
        "def benchmark():\n",
        "    sizes = [100, 500, 1000, 5000, 10000]\n",
        "    sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "    func_times = [[] for _ in sort_funcs]  # ë™ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "\n",
        "    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n",
        "    for size in sizes:\n",
        "        arr = [random.randint(0, 10000) for _ in range(size)]   # ì •ìˆ˜(ì–‘ì˜ ì •ìˆ˜)\n",
        "        results = measure_time(sort_funcs, arr)\n",
        "        for idx, val in enumerate(results):\n",
        "            func_times[idx].append(val)\n",
        "\n",
        "    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for idx, sort_func in enumerate(sort_funcs):\n",
        "        plt.plot(sizes, func_times[idx], label=f\"{sort_func.__name__}\", marker='o')\n",
        "        print(f\"{sort_func.__name__}\\t\",func_times[idx] )\n",
        "\n",
        "    plt.xlabel(\"Input Size\")\n",
        "    plt.ylabel(\"Execution Time (seconds)\")\n",
        "    plt.title(f\"{sort_func.__name__} Time Complexity Analysis\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "benchmark()"
      ],
      "metadata": {
        "id": "em-JlDUrSuNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ë‹¤ì–‘í•œ ì¢…ë¥˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì‹œê°„ ì¸¡ì •í•˜ê¸°\n",
        "- ë‹¤ì–‘í•œ ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ì˜ ì‹œê°„ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ì—¬ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ê¸°\n",
        "- sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "    1. ì •ìˆ˜(ì–‘ì˜ ì •ìˆ˜) : ì´ë¯¸ ì•ì—ì„œ í…ŒìŠ¤íŠ¸ í•¨\n",
        "    2. ì •ìˆ˜(ìŒìˆ˜í¬í•¨)\n",
        "    3. np.array ì •ìˆ˜"
      ],
      "metadata": {
        "id": "qK9Im5RpcWE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë²¤ì¹˜ë§ˆí¬ í•¨ìˆ˜\n",
        "def benchmark():\n",
        "    sizes = [100, 500, 1000, 5000, 10000]\n",
        "    sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "    func_times = [[] for _ in sort_funcs]  # ë™ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "\n",
        "    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n",
        "    for size in sizes:\n",
        "        # arr = [random.randint(0, 10000) for _ in range(size)]         # ì •ìˆ˜(ì–‘ì˜ ì •ìˆ˜)\n",
        "        arr = [random.randint(-10000, 10000) for _ in range(size)]    # ì •ìˆ˜(ìŒìˆ˜í¬í•¨)\n",
        "        # arr = [np.random.randint(-10000, 10000) for _ in range(size)]   # np.array ì •ìˆ˜\n",
        "        results = measure_time(sort_funcs, arr)\n",
        "        for idx, val in enumerate(results):\n",
        "            func_times[idx].append(val)\n",
        "\n",
        "    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for idx, sort_func in enumerate(sort_funcs):\n",
        "        plt.plot(sizes, func_times[idx], label=f\"{sort_func.__name__}\", marker='o')\n",
        "        # print(f\"{sort_func.__name__}\\t\",func_times[idx] )\n",
        "\n",
        "    plt.xlabel(\"Input Size\")\n",
        "    plt.ylabel(\"Execution Time (seconds)\")\n",
        "    plt.title(\"Algorithm Time Complexity Analysis\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "benchmark()"
      ],
      "metadata": {
        "id": "o3ANPUrhLdLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qphUUKIsNMvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. ë¬¸ìì—´ ë°ì´í„° ì •ë ¬**"
      ],
      "metadata": {
        "id": "CCX8QjC0BbUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ë¬¸ìì—´ ë°ì´í„° ìƒì„±í•˜ê¸°**"
      ],
      "metadata": {
        "id": "HMpgfdRW5aCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì„ì˜ì˜ ì˜ì–´ ë‹¨ì–´ ìƒì„±**\n",
        "    - nltk corpus ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©(Natural Language Toolkit)"
      ],
      "metadata": {
        "id": "X8v5j1BCDTFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„ì˜ì˜ ë¬¸ìì—´ ìƒì„±\n",
        "import random\n",
        "import nltk             # NLTK :: Natural Language Toolkit\n",
        "\n",
        "# ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œì—ë§Œ í•„ìš”)\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "\n",
        "def generate_random_words(n=10000):\n",
        "    word_list = words.words()\n",
        "    # ë„ˆë¬´ ê¸´ ë‹¨ì–´ë¥¼ ì œì™¸í•˜ê³  ì§§ê³  ì¼ë°˜ì ì¸ ë‹¨ì–´ ìœ„ì£¼ë¡œ ì„ íƒ (ì˜ˆ: 3~8ì)\n",
        "    filtered_words = [w for w in word_list if 3 <= len(w) <= 8 and w.isalpha()]\n",
        "    return random.sample(filtered_words, n)\n",
        "\n",
        "# ì‹¤í–‰\n",
        "alphabet_words = generate_random_words()\n",
        "print('ìƒì„±ëœ ë‹¨ì–´ ê°œìˆ˜: ', len(alphabet_words))\n",
        "print(alphabet_words)\n",
        "# alphabet_words = ['braiding', 'bervie', 'uptable', 'awane', 'Cradock']\n"
      ],
      "metadata": {
        "id": "riWBSBFj5aO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì„ì˜ì˜ í•œê¸€ ë‹¨ì–´ ìƒì„±**\n",
        "    - ì™„ì„±í˜• í•œê¸€ ìŒì ˆ(U+AC00 ~ U+D7A3)ì€ ì´ˆì„± Ã— ì¤‘ì„± Ã— ì¢…ì„±ì˜ ì¡°í•©ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ë‹¤.\n",
        "    - ìœ ë‹ˆì½”ë“œ ìµœëŒ€ 4bytesë¡œ êµ¬ì„±\n",
        "    - ìœ ë‹ˆì½”ë“œëŠ” ì €ì¥/ì „ì†¡ ì‹œ UTF-8, UTF-16, UTF-32 ê°™ì€ ì¸ì½”ë”© ë°©ì‹ ì‚¬ìš©"
      ],
      "metadata": {
        "id": "g7npb7GqEmG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ì´ˆì„±, ì¤‘ì„±, ì¢…ì„± ë¦¬ìŠ¤íŠ¸\n",
        "CHOSUNG = ['ã„±','ã„²','ã„´','ã„·','ã„¸','ã„¹','ã…','ã…‚','ã…ƒ','ã……','ã…†','ã…‡','ã…ˆ','ã…‰','ã…Š','ã…‹','ã…Œ','ã…','ã…']\n",
        "JUNGSUNG = ['ã…','ã…','ã…‘','ã…’','ã…“','ã…”','ã…•','ã…–','ã…—','ã…˜','ã…™','ã…š','ã…›','ã…œ','ã…','ã…','ã…Ÿ','ã… ','ã…¡','ã…¢','ã…£']\n",
        "JONGSUNG = ['','ã„±','ã„²','ã„³','ã„´','ã„µ','ã„¶','ã„·','ã„¹','ã„º','ã„»','ã„¼','ã„½','ã„¾','ã„¿','ã…€','ã…','ã…‚','ã…„','ã……','ã…†','ã…‡','ã…ˆ','ã…Š','ã…‹','ã…Œ','ã…','ã…']\n",
        "\n",
        "def make_random_syllable():\n",
        "    # ì´ˆì„±, ì¤‘ì„±, ì¢…ì„± ì„ íƒ\n",
        "    cho = random.choice(CHOSUNG)\n",
        "    jung = random.choice(JUNGSUNG)\n",
        "    jong = random.choice(JONGSUNG)\n",
        "\n",
        "    # ìœ ë‹ˆì½”ë“œ ê³„ì‚°\n",
        "    cho_index = CHOSUNG.index(cho)\n",
        "    jung_index = JUNGSUNG.index(jung)\n",
        "    jong_index = JONGSUNG.index(jong)\n",
        "\n",
        "    '''\n",
        "    ìœ ë‹ˆì½”ë“œ : ì‹œì‘ìœ„ì¹˜(0xAC00:ê°€), ì´ˆì„±(19ê°œ),ì¤‘ì„±(21ê°œ),ì¢…ì„±(28ê°œ)\n",
        "    ex: ê°•'ì˜ êµ¬ì„±: ã„±(ì´ˆì„±) + ã…(ì¤‘ì„±) + ã…‡(ì¢…ì„±)\n",
        "        ì¸ë±ìŠ¤: ì´ˆì„± 'ã„±' = 0,\n",
        "                ì¤‘ì„± 'ã…' = 0,\n",
        "                ì¤‘ì„± 'ã…' = 0\n",
        "        code = 0xAC00 + (0 * 21 * 28) + (0 * 28) + 21\n",
        "             = 0xAC00 + 21\n",
        "             = 0xAC15  â†’ chr(0xAC15) == 'ê°•'\n",
        "    '''\n",
        "    code = 0xAC00 + (cho_index * 21 * 28) + (jung_index * 28) + jong_index\n",
        "\n",
        "    return chr(code)\n",
        "\n",
        "def generate_random_korean_word(length=2):\n",
        "    return ''.join(make_random_syllable() for _ in range(length))\n",
        "\n",
        "# ì‹¤í–‰ ì˜ˆ\n",
        "print(generate_random_korean_word())       # ì˜ˆ: ëˆ ê°•\n",
        "print(generate_random_korean_word(3))      # ì˜ˆ: ì³”ì¿”í—\n"
      ],
      "metadata": {
        "id": "l-IMw8Q8Gwib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì˜ë¯¸ ìˆëŠ” í•œê¸€ ë‹¨ì–´ ì‚¬ìš©\n",
        "    - ìì£¼ ì“°ì´ëŠ” í•œêµ­ì–´ ë‚±ë§: https://ko.wiktionary.org/wiki/%EB%B6%80%EB%A1%9D:%EC%9E%90%EC%A3%BC_%EC%93%B0%EC%9D%B4%EB%8A%94_%ED%95%9C%EA%B5%AD%EC%96%B4_%EB%82%B1%EB%A7%90_5800"
      ],
      "metadata": {
        "id": "hTIxxuq4IXa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# ìƒ˜í”Œ í•œê¸€ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸\n",
        "korean_words = [\n",
        "    \"ì‚¬ê³¼\", \"ë°”ë‚˜ë‚˜\", \"ê³ ì–‘ì´\", \"ê°•ì•„ì§€\", \"í•™êµ\", \"ìš°ì‚°\", \"ë°”ëŒ\", \"í•˜ëŠ˜\", \"ë°”ë‹¤\",\n",
        "    \"ì‚°ì±…\", \"ìŒì•…\", \"ì—¬í–‰\", \"ì¹œêµ¬\", \"ì‚¬ë‘\", \"ê°€ì¡±\", \"ë¬¸í™”\", \"ì–¸ì–´\", \"ê¸°ìˆ \", \"ìì—°\", \"ê³„ì ˆ\"\n",
        "]\n",
        "\n",
        "def generate_random_korean_word(n):\n",
        "    return random.choices(korean_words, k=n)\n",
        "\n",
        "# ì‹¤í–‰\n",
        "print(generate_random_korean_word(5))\n"
      ],
      "metadata": {
        "id": "BmRuteF6IYCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** (êµ­ì–´ì›) í•œê¸€ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°  \n",
        "- ì•ì—ì„œ ì‚¬ìš©í•œ \"ìì£¼ ì“°ì´ëŠ” í•œêµ­ì–´ ë‚±ë§ 5800\" ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì™€ ë‹¨ì–´ 5000ê°œë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì§€ì •í•˜ê¸°.\n",
        "    1. ì‚¬ì´íŠ¸ì—ì„œ í•œê¸€ ë‹¨ì–´ ë³µì‚¬í•˜ê¸°\n",
        "    2. ë©”ëª¨ì¥ì„ ì—´ì–´ ë³µì‚¬í•˜ê³  korean_words.txtë¡œ ì €ì¥\n",
        "    3. ì½”ë“œì—ì„œ txt íŒŒì¼ ì½ì–´ì˜¤ê¸°\n",
        "    4. ì„ì˜ì˜ 1000ê°œ ë¦¬ìŠ¤íŠ¸ korean_words ë³€ìˆ˜ì— ì§€ì •í•˜ê¸°"
      ],
      "metadata": {
        "id": "eY0MZ6bvRAod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# GitHub raw íŒŒì¼ URL\n",
        "url = 'https://raw.githubusercontent.com/Joyschool/gachon-algorithm-2025/main/korean_words.txt'\n",
        "\n",
        "filename = 'korean_words.txt'\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "print(f\"âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {filename}\")\n",
        "\n",
        "\n",
        "with open(filename) as f:\n",
        "    data = f.read()\n",
        "    # print(data)\n",
        "    list1 = data.split('\\n')\n",
        "    korean_words = random.choices(list1, k=5000)\n",
        "    print(korean_words)\n",
        "\n",
        "print('ë‹¨ì–´ ê°œìˆ˜: ', len(korean_words))\n"
      ],
      "metadata": {
        "id": "ZnnKw07dRM1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3k44m_yGLHrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ë¬¸ìì—´ ë°ì´í„° ì •ë ¬í•˜ê¸°**"
      ],
      "metadata": {
        "id": "LwQGl0EfLE44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì •ë ¬ìˆœì„œ**\n",
        "    - **ì•ŒíŒŒë²³ ì •ë ¬** : **ëŒ€ë¬¸ì->ì†Œë¬¸ì** ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì •ë ¬\n",
        "    - **í•œê¸€ ì •ë ¬**: ê°€ë‚˜ë‹¤ ìˆœì„œë¡œ ì •ë ¬(ìœ ë‹ˆì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬)\n",
        "    - **ì•ŒíŒŒë²³ + í•œê¸€ ì •ë ¬** : ì•ŒíŒŒë²³ì´ ë¨¼ì € ë‚˜ì˜¤ê³  í•œê¸€ì´ ë‚˜ì¤‘ì— ë‚˜ì˜µë‹ˆë‹¤. (í•œê¸€ì´ ìœ ë‹ˆì½”ë“œìƒ ë” ë’¤ì— ë‚˜ì˜´)"
      ],
      "metadata": {
        "id": "0edRytfT8WYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
        "# -------------------------------\n",
        "test_cases = [\n",
        "    (['braiding', 'bervie', 'uptable', 'awane', 'Cradock'], \"Alphabet only\"),\n",
        "    (['í”¼ì', 'ìì „ê±°', 'ê¹ƒë°œ', 'ë‹¬ê±€', 'ê²Œì„'], \"Korean only\"),\n",
        "    ([\"banana\", \"ì‚¬ê³¼\", \"apple\", \"í† ë¼\", 'Cradock', \"ê³ ì–‘ì´\"], \"Alphabet + Korean\"),\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# ì•Œê³ ë¦¬ì¦˜ ë°˜ë³µ í…ŒìŠ¤íŠ¸\n",
        "# -------------------------------\n",
        "sort_algorithms = [bubble_sort, selection_sort, insertion_sort]\n",
        "# sort_algorithms = [bubble_sort]\n",
        "for sort_func in sort_algorithms:\n",
        "    print(f\"\\nğŸ” Testing: {sort_func.__name__}\")\n",
        "    for data, label in test_cases:\n",
        "        test_sort(sort_func, data, label, True)\n"
      ],
      "metadata": {
        "id": "JujH2tlaORQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ë‹¤ëŸ‰ì˜ ë¬¸ìì—´ ì •ë ¬ í…ŒìŠ¤íŠ¸í•˜ê¸°\n",
        "- ì•ì—ì„œ ì¤€ë¹„í•œ alphabet_wordsì™€ korean_words, alphabet_words+korean_words ë°ì´í„°ë¥¼\n",
        "- test_casesë¡œ ë§Œë“¤ì–´ test_sort í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì •ë ¬ì„ ì§„í–‰ì‹œì¼œ ë³´ì„¸ìš”."
      ],
      "metadata": {
        "id": "CMwkXa-vaDOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¬¸ìì—´ ë°ì´í„° ì •ë ¬\n",
        "mixed_words = alphabet_words+korean_words\n",
        "random.shuffle(mixed_words)\n",
        "test_cases = [  (alphabet_words, 'alphabet_words'),\n",
        "                (korean_words, 'korean_words'),\n",
        "                (mixed_words, 'mixed_words')]\n",
        "\n",
        "sort_algorithms = [bubble_sort, selection_sort, insertion_sort]\n",
        "# sort_algorithms = [bubble_sort]\n",
        "for sort_func in sort_algorithms:\n",
        "    print(f\"\\nğŸ” Testing: {sort_func.__name__}\")\n",
        "    for data, label in test_cases:\n",
        "        test_sort(sort_func, data, label)"
      ],
      "metadata": {
        "id": "i_j5d-K0aMAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ë‹¤ëŸ‰ì˜ ë¬¸ìì—´ ë°ì´í„° ì„±ëŠ¥ ì‹œê°í™”í•˜ê¸°\n",
        "ì•ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì•„ë˜ ì¡°ê±´ì— ë§ê²Œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ì‹œê°í™”í•˜ì‹œì˜¤.\n",
        "- ë°ì´í„° í¬ê¸°   : sizes = [100, 500, 1000, 5000]\n",
        "- ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ : sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "- ì•Œê³ ë¦¬ì¦˜ë³„ ì¸¡ì • ì‹œê°„ ì €ì¥: func_times = [[] for _ in sort_funcs]  # ë™ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "- ì •ë ¬ ë°ì´í„°:\n",
        "    1. arr = alphabet_words (ì˜ì–´ ë‹¨ì–´)\n",
        "    2. arr = korean_words(í•œê¸€ ë‹¨ì–´)\n",
        "    3. arr = mixed_words(í˜¼í•©)"
      ],
      "metadata": {
        "id": "92rRjg1pfogs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë²¤ì¹˜ë§ˆí¬ í•¨ìˆ˜\n",
        "def benchmark():\n",
        "    sizes = [100, 500, 1000, 5000]\n",
        "    sort_funcs = [bubble_sort, selection_sort, insertion_sort, merge_sort, quick_sort]\n",
        "    func_times = [[] for _ in sort_funcs]  # ë™ì  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "\n",
        "    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n",
        "    for size in sizes:\n",
        "        # arr = alphabet_words    # alphabet_words\n",
        "        # arr = korean_words      # korean_words\n",
        "        arr = mixed_words       # mixed_words\n",
        "        results = measure_time(sort_funcs, arr)\n",
        "        for idx, val in enumerate(results):\n",
        "            func_times[idx].append(val)\n",
        "\n",
        "    # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for idx, sort_func in enumerate(sort_funcs):\n",
        "        plt.plot(sizes, func_times[idx], label=f\"{sort_func.__name__}\", marker='o')\n",
        "        # print(f\"{sort_func.__name__}\\t\",func_times[idx] )\n",
        "\n",
        "    plt.xlabel(\"Input Size\")\n",
        "    plt.ylabel(\"Execution Time (seconds)\")\n",
        "    plt.title(\"Algorithm Time Complexity Analysis\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "benchmark()"
      ],
      "metadata": {
        "id": "3M7njrvxf6AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **í˜¼í•© ë°ì´í„° ì •ë ¬í•˜ê¸°**(ìˆ«ì + ì˜ë¬¸ + í•œê¸€)"
      ],
      "metadata": {
        "id": "XQlKSjRGPIpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_list = ['123', 'abc', 'ê°€ë‚˜', 'ABC', '456', 'ë‹¤ë¼', 'Abc', '789', 'ë‚˜ë‹¤', 'def']\n"
      ],
      "metadata": {
        "id": "VrDpu2IvnZKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ê¸°ë³¸ ì •ë ¬**(ìœ ë‹ˆì½”ë“œ ê¸°ë°˜)\n",
        "    - ìˆ«ì > ì•ŒíŒŒë²³(ëŒ€ë¬¸ì > ì†Œë¬¸ì) > í•œê¸€(ìœ ë‹ˆì½”ë“œ ìˆœì„œ: ê°€,ë‚˜,ë‹¤)"
      ],
      "metadata": {
        "id": "B7KoORzjnfSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_list = sorted(mixed_list)\n",
        "sorted_list\n",
        "# ìˆ«ì > ì•ŒíŒŒë²³(ëŒ€ë¬¸ì > ì†Œë¬¸ì) > í•œê¸€(ìœ ë‹ˆì½”ë“œ ìˆœì„œ: ê°€,ë‚˜,ë‹¤)"
      ],
      "metadata": {
        "id": "E5M67_tgnlU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì»¤ìŠ¤í…€ ì •ë ¬ ê¸°ì¤€ ë§Œë“¤ê¸°**\n",
        "    - ìˆ«ì > ì•ŒíŒŒë²³ > í•œê¸€ ìˆœì„œ"
      ],
      "metadata": {
        "id": "l5y-wZwIn3mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¢…ë¥˜ë³„ ê·¸ë£¹ ë‚˜ëˆˆ í›„ ì •ë ¬\n",
        "\n",
        "import re\n",
        "\n",
        "def get_type_priority(s):\n",
        "    if s.isdigit():\n",
        "        return (0, s)  # ìˆ«ì ê·¸ë£¹\n",
        "    elif re.match(r'^[a-zA-Z]+$', s):\n",
        "        return (1, s.lower())  # ì•ŒíŒŒë²³ ê·¸ë£¹ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ X)\n",
        "    elif re.match(r'^[ê°€-í£]+$', s):\n",
        "        return (2, s)  # í•œê¸€ ê·¸ë£¹\n",
        "    else:\n",
        "        return (3, s)  # ê¸°íƒ€\n",
        "\n",
        "sorted_list = sorted(mixed_list, key=get_type_priority)\n",
        "sorted_list\n",
        "# ìˆ«ì > ì•ŒíŒŒë²³ > í•œê¸€(ìœ ë‹ˆì½”ë“œ ìˆœì„œ: ê°€,ë‚˜,ë‹¤)"
      ],
      "metadata": {
        "id": "iUF5EMuVn9jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " - **ë¡œì¼€ì¼ì„ ê³ ë ¤í•œ ì •ë ¬** (í•œê¸€ ê°€ë‚˜ë‹¤ ìˆœ ë“±)\n",
        "    - ìˆ«ì > ì•ŒíŒŒë²³(ëŒ€ë¬¸ì > ì†Œë¬¸ì) > í•œê¸€(ìœ ë‹ˆì½”ë“œ ìˆœì„œ: ê°€,ë‚˜,ë‹¤)"
      ],
      "metadata": {
        "id": "Ak1PH0ezobml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "from functools import cmp_to_key\n",
        "\n",
        "# ì‚¬ìš© ê°€ëŠ¥í•œ ë¡œì¼€ì¼ ì¶œë ¥\n",
        "print(locale.locale_alias['ko_kr'])  # Windowsì¼ ê²½ìš° 'kor'ë¡œ ì¶œë ¥ë  ìˆ˜ë„ ìˆìŒ\n",
        "\n",
        "# ë¡œì¼€ì¼ ì„¤ì • ì‹œë„ (ìš´ì˜ì²´ì œì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)\n",
        "try:\n",
        "    locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')  # Linux/macOS\n",
        "except locale.Error:\n",
        "    try:\n",
        "        locale.setlocale(locale.LC_ALL, 'korean')   # Windows ìš©\n",
        "    except locale.Error:\n",
        "        print(\"í•œêµ­ì–´ ë¡œì¼€ì¼ì„ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì—ì„œ ì§€ì›ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# locale.strcollë¥¼ keyë¡œ ì‚¬ìš©\n",
        "sorted_list = sorted(mixed_list, key=cmp_to_key(locale.strcoll))\n",
        "sorted_list\n",
        "#"
      ],
      "metadata": {
        "id": "A3pWu-p_ofRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "96KZxucEKvKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. ì´ë¯¸ì§€ ë°ì´í„° ì •ë ¬**"
      ],
      "metadata": {
        "id": "g6ASuk25_yDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì´ë¯¸ì§€ ê°œìš”**\n",
        "\n",
        "- **í”½ì…€ pixel**ì´ë€?\n",
        "    - ì´ë¯¸ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ì‘ì€ ë‹¨ìœ„ (í™”ì†Œ)\n",
        "    - í•˜ë‚˜ì˜ í”½ì…€ì€ ìƒ‰ìƒ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë°ì´í„° ë‹¨ìœ„\n",
        "    - í”½ì…€ì˜ í¬ê¸°ëŠ” **ì»¬ëŸ¬ í‘œí˜„ ë°©ì‹(ë¹„íŠ¸ ëìŠ¤, ë¹„íŠ¸ ê¹Šì´)**ì— ë”°ë¼ ë‹¬ë¼ì§„ë‹¤."
      ],
      "metadata": {
        "id": "F5etzkXjeaOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ì»¬ëŸ¬ ëª¨ë“œë³„ í”½ì…€ í¬ê¸°**\n"
      ],
      "metadata": {
        "id": "jSU3s7QmerMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|ì»¬ëŸ¬ ëª¨ë“œ |ì„¤ëª… | ë¹„íŠ¸ ìˆ˜|ë°”ì´íŠ¸ ìˆ˜ |\n",
        "|--- |--- | ---|--- |\n",
        "|1-bit (í‘ë°±)|0 or 1 (í‘/ë°±ë§Œ)|1ë¹„íŠ¸|1/8 ë°”ì´íŠ¸|\n",
        "|L (Grayscale)|ë°ê¸°ë§Œ í‘œí˜„ (0~255)|8ë¹„íŠ¸|1 ë°”ì´íŠ¸|\n",
        "|RGB|\"R, G, B ê° ì±„ë„ì´ 8ë¹„íŠ¸\"|24ë¹„íŠ¸|3 ë°”ì´íŠ¸|\n",
        "|RGBA|RGB + Alpha(íˆ¬ëª…ë„)|32ë¹„íŠ¸|4 ë°”ì´íŠ¸|\n",
        "|CMYK|\"ì¸ì‡„ìš© ìƒ‰ìƒ(Cyan, Magenta, Yellow, Black)\"|32ë¹„íŠ¸|4 ë°”ì´íŠ¸|\n",
        "|16-bit grayscale|ê³ í•´ìƒë„ í‘ë°± (0~65535)|16ë¹„íŠ¸|2 ë°”ì´íŠ¸|\n",
        "|HDR ì´ë¯¸ì§€ (ì˜ˆ: float32 RGB)|ê³ ì •ë°€ ì´ë¯¸ì§€ í‘œí˜„|96ë¹„íŠ¸|12 ë°”ì´íŠ¸|\n",
        "\n"
      ],
      "metadata": {
        "id": "ItSz_9Fue-i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "img = Image.open(\"cat.jpg\")\n",
        "print(\"ëª¨ë“œ:\", img.mode)  # ì˜ˆ: 'RGB'\n",
        "print(\"í•´ìƒë„:\", img.size)  # (width, height)\n",
        "\n",
        "# í”½ì…€ ìˆ˜\n",
        "width, height = img.size\n",
        "pixels = width * height\n",
        "\n",
        "# ì´ ë°”ì´íŠ¸ ìˆ˜ (RGB ê¸°ì¤€)\n",
        "total_bytes = pixels * 3  # RGBëŠ” í”½ì…€ë‹¹ 3ë°”ì´íŠ¸\n",
        "print(f\"ì´ ë°”ì´íŠ¸ ìˆ˜ (ì¶”ì •): {total_bytes:,} Bytes\")\n"
      ],
      "metadata": {
        "id": "iP3NBXhyfvFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„í•˜ê¸°**"
      ],
      "metadata": {
        "id": "y8PbNWy7EPEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ì´ë¯¸ì§€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "1.  https://www.pexels.com/api/ íšŒì›ê°€ì…\n",
        "2. \"Get Started\" í´ë¦­ í›„ API Key ë³µì‚¬\n",
        "3. SEARCH_QUERY : cats(jpg), dogs(jpg), cars(gif), flowers(png)"
      ],
      "metadata": {
        "id": "lUbG_ahL7KWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # tqdm: ê¸´ ì‹œê°„ ë™ì•ˆ ì‹¤í–‰ë˜ëŠ” ë°˜ë³µë¬¸ì˜ ì§„í–‰ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import time\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    time.sleep(0.1) # ê° ë°˜ë³µì— ì•½ê°„ì˜ ì‹œê°„ ì§€ì—°ì„ ì¤ë‹ˆë‹¤.\n",
        "print(\"ì‘ì—… ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "5uJOMYH--yzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# â¡ï¸ Pexels API Key ì…ë ¥\n",
        "PEXELS_API_KEY = 'your_api_key'  # ì—¬ê¸°ì— ë³¸ì¸ì˜ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
        "\n",
        "# â¡ï¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ë° ì €ì¥ í´ë”\n",
        "SEARCH_QUERY = 'cats'\n",
        "SAVE_FOLDER = 'images'\n",
        "IMAGES_TO_DOWNLOAD = 100  # ì´ ëª‡ ì¥ ë‹¤ìš´ë¡œë“œí•  ê²ƒì¸ì§€\n",
        "\n",
        "# â¡ï¸ API ìš”ì²­ í•¨ìˆ˜\n",
        "def search_images(query, per_page=30, page=1):\n",
        "    headers = {\n",
        "        \"Authorization\": PEXELS_API_KEY\n",
        "    }\n",
        "    url = f\"https://api.pexels.com/v1/search?query={query}&per_page={per_page}&page={page}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "# â¡ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜\n",
        "def download_image(url, save_path):\n",
        "    r = requests.get(url, stream=True)\n",
        "    if r.status_code == 200:\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(1024):  # 1024ë°”ì´íŠ¸ í¬ê¸°ì˜ ë©ì–´ë¦¬(chunk)ë¡œ ë‚˜ëˆ„ì–´ ìˆœíšŒ ì €ì¥\n",
        "                f.write(chunk)\n",
        "\n",
        "# â¡ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰ & ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
        "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
        "\n",
        "downloaded = 0\n",
        "page = 1\n",
        "while downloaded < IMAGES_TO_DOWNLOAD:\n",
        "    data = search_images(SEARCH_QUERY, per_page=30, page=page)\n",
        "    photos = data.get('photos', [])\n",
        "\n",
        "    if not photos:\n",
        "        print(\"ì´ë¯¸ì§€ë¥¼ ë” ì´ìƒ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        break\n",
        "\n",
        "    for photo in photos:\n",
        "        image_url = photo['src']['large']\n",
        "        filename = f\"{SEARCH_QUERY}_{downloaded+1}.png\"\n",
        "        save_path = os.path.join(SAVE_FOLDER, filename)\n",
        "        download_image(image_url, save_path)\n",
        "        downloaded += 1\n",
        "        tqdm.write(f\"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
        "\n",
        "        if downloaded >= IMAGES_TO_DOWNLOAD:\n",
        "            break\n",
        "    page += 1\n",
        "\n",
        "print(f\"\\nì´ {downloaded}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ '{SAVE_FOLDER}' í´ë”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hsP1Axk87TN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì´ë¯¸ì§€ ë°ì´í„° ì†ì„±**"
      ],
      "metadata": {
        "id": "NgzqAlIs34_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì´ë¯¸ì§€ íŒŒì¼ : JPG, PNG ë“± í™•ì¥ìë¥¼ ê°–ëŠ” íŒŒì¼\n",
        "- **ì´ë¯¸ì§€ ì†ì„±**:\n",
        "    - íŒŒì¼ëª…(íŒŒì¼ëª…/ë‚ ì§œ/ì´ë¦„)\n",
        "    - íŒŒì¼ ìš©ëŸ‰ (bytes)\n",
        "    - í•´ìƒë„ (Width x Height)\n",
        "    - ì´ë¯¸ì§€ ëª¨ë“œ (RGB, L ë“±) : '1' (Binary image), 'L' (Grayscale image), 'RGB' (Red, Green, Blue)\n",
        "    - ë°ê¸° (Grayscale í‰ê· ê°’)\n",
        "    - ìƒ‰ìƒ (í‰ê·  RGB, ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ë“±)\n"
      ],
      "metadata": {
        "id": "vA7f1rnV39lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ì´ë¯¸ì§€ ë°ì´í„° ì†ì„± ì¶”ì¶œí•˜ê¸°"
      ],
      "metadata": {
        "id": "EVZoGmb45beb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow numpy pandas"
      ],
      "metadata": {
        "id": "bgFY341q6e7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def extract_image_features(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # â¡ï¸ ê¸°ë³¸ ì†ì„±\n",
        "        filename = os.path.basename(image_path)\n",
        "        file_size = os.path.getsize(image_path)  # bytes\n",
        "        width, height = img.size\n",
        "        mode = img.mode\n",
        "\n",
        "        # â¡ï¸ ë°ê¸° (Grayscale ë³€í™˜ í›„ í‰ê· )\n",
        "        grayscale = img.convert('L')\n",
        "        brightness = np.array(grayscale).mean()\n",
        "\n",
        "        # â¡ï¸ RGB í‰ê· \n",
        "        if img.mode in ['RGB', 'RGBA']:\n",
        "            rgb_array = np.array(img.convert('RGB'))\n",
        "            avg_color = rgb_array.mean(axis=(0, 1))  # R, G, B í‰ê· ê°’\n",
        "        else:\n",
        "            avg_color = [None, None, None]\n",
        "\n",
        "        return {\n",
        "            'íŒŒì¼ëª…': filename,\n",
        "            'íŒŒì¼í¬ê¸°(Bytes)': file_size,\n",
        "            'í•´ìƒë„': f\"{width}x{height}\",\n",
        "            'ëª¨ë“œ': mode,\n",
        "            'í‰ê· ë°ê¸°': round(brightness, 2),\n",
        "            'Rí‰ê· ': round(avg_color[0], 2) if avg_color[0] else None,\n",
        "            'Gí‰ê· ': round(avg_color[1], 2) if avg_color[1] else None,\n",
        "            'Bí‰ê· ': round(avg_color[2], 2) if avg_color[2] else None\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
        "image_folder = 'images'  # ì—¬ê¸°ì— ì‹¤ì œ ê²½ë¡œ ì…ë ¥\n",
        "image_files = [os.path.join(image_folder, f)\n",
        "               for f in os.listdir(image_folder)\n",
        "               if f.lower().endswith(('.jpg', '.jpeg', '.png','gif'))]\n",
        "\n",
        "# ì†ì„± ì¶”ì¶œ\n",
        "image_data = [extract_image_features(img_path) for img_path in image_files]\n",
        "image_data = [d for d in image_data if d is not None]\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
        "df = pd.DataFrame(image_data)\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "00mg3zIm5tgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** ì´ë¯¸ì§€ ì†ì„± ë°ì´í„° ì •ë ¬"
      ],
      "metadata": {
        "id": "ooZB0hYPGLsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Pandas DataFrame ì»¬ëŸ¼ê¸°ì¤€ ì •ë ¬í•˜ê¸°**"
      ],
      "metadata": {
        "id": "mDrx8aEcHBDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê· ë°ê¸° ì»¬ëŸ¼ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê¸°\n",
        "df.sort_values(by='íŒŒì¼ëª…', ascending=True).head(5)"
      ],
      "metadata": {
        "id": "oUbB0w_cErWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ['í•´ìƒë„','íŒŒì¼í¬ê¸°(Bytes)'] ì»¬ëŸ¼ìˆœìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê¸°\n",
        "df.sort_values(by='í‰ê· ë°ê¸°', ascending=False).head(5)\n",
        "df.sort_values(by=['í•´ìƒë„','íŒŒì¼í¬ê¸°(Bytes)'], ascending=[False,True]).head(5)"
      ],
      "metadata": {
        "id": "H9sN_t4vFok4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **ë°ê¸° ê¸°ë°˜ ì •ë ¬í•˜ê¸°**\n",
        "<br>ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•œ í›„, í‰ê·  ë°ê¸°ë¥¼ êµ¬í•´ì„œ ì •ë ¬í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "PBRcRjOr4XUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ê¸° ê¸°ë°˜ ì •ë ¬\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# â¡ï¸ ì´ë¯¸ì§€ë¥¼ ë°ê¸° ê°’ìœ¼ë¡œ ì •ë ¬í•˜ê¸°\n",
        "def get_avg_brightness(image_path):\n",
        "    image = Image.open(image_path).convert('L')  # L = grayscale\n",
        "    arr = np.array(image)\n",
        "    return arr.mean()\n",
        "\n",
        "image_folder = 'images'     # ì´ë¯¸ì§€ í´ë”\n",
        "# image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
        "image_files = [f for f in os.listdir(image_folder)]\n",
        "\n",
        "# ë‚´ì¥ ì •ë ¬ í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ì •ë ¬\n",
        "sorted_images = sorted(\n",
        "    image_files,\n",
        "    key=lambda x: get_avg_brightness(os.path.join(image_folder, x))\n",
        ")\n",
        "\n",
        "print(sorted_images[:3])    # ë°ê¸°ê°’ ë‚´ë¦¼ì°¨ìˆœ\n",
        "print(sorted_images[::10])\n"
      ],
      "metadata": {
        "id": "uPRZ5ypqBa2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì´ë¯¸ì§€ ê·¸ë˜í”„ì— ì‹œê°í™”í•˜ê¸°"
      ],
      "metadata": {
        "id": "TZr346DtNmG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# â¡ï¸ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ê¸°\n",
        "def visualize_resized_images(image_paths):\n",
        "    \"\"\"\n",
        "    1.ì£¼ì–´ì§„ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì˜ ì´ë¯¸ì§€ë“¤ì„ ë™ì¼í•œ í¬ê¸°ë¡œ ì¡°ì •(200x200)\n",
        "    2.2í–‰ 3ì—´ (ë˜ëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ì— ë”°ë¥¸ ì—´) ê·¸ë˜í”„ì— ì‹œê°í™”\n",
        "    3.1í–‰ì—ëŠ” ì›ë³¸ ì´ë¯¸ì§€, 2í–‰ì—ëŠ” grayscale ì´ë¯¸ì§€ ë‚˜íƒ€ëƒ„\n",
        "    \"\"\"\n",
        "    target_size = (200, 200)  # ëª©í‘œë¡œ í•˜ëŠ” ì´ë¯¸ì§€ í¬ê¸° (ì›í•˜ëŠ” ê°€ë¡œ, ì„¸ë¡œ í¬ê¸°ë¡œ ë³€ê²½ ê°€ëŠ¥)\n",
        "    original_images = []\n",
        "    grayscale_images = []\n",
        "\n",
        "    for path in image_paths:\n",
        "        try:\n",
        "            img = Image.open(path)\n",
        "            resized_img = img.resize(target_size)       # í¬ê¸° ë³€í™˜\n",
        "            original_images.append(resized_img)\n",
        "            grayscale_img = resized_img.convert(\"L\")    # Grayscaleë¡œ ë³€í™˜\n",
        "            grayscale_images.append(grayscale_img)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"ê²½ë¡œ '{path}'ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "    if len(original_images) > 0:\n",
        "        num_images = len(original_images)\n",
        "        fig, axes = plt.subplots(2, num_images, figsize=(2 * num_images, 4)) # 2í–‰ìœ¼ë¡œ ë³€ê²½, ì „ì²´ ê·¸ë˜í”„ ë†’ì´ ì¡°ì ˆ\n",
        "\n",
        "        if num_images == 1:\n",
        "            axes = [[axes[0]], [axes[1]]] # ì´ë¯¸ì§€ê°€ í•˜ë‚˜ì¼ ê²½ìš° axesë¥¼ 2D ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì²˜ë¦¬\n",
        "\n",
        "        for i in range(num_images):\n",
        "            # ì›ë³¸ ì´ë¯¸ì§€ ì‹œê°í™” (1í–‰)\n",
        "            original_img_array = np.array(original_images[i])\n",
        "            axes[0][i].imshow(original_img_array)\n",
        "            axes[0][i].set_title(f\"Original {i+1}\")\n",
        "            axes[0][i].axis('off')\n",
        "\n",
        "            # grayscale ì´ë¯¸ì§€ ì‹œê°í™” (2í–‰)\n",
        "            grayscale_img_array = np.array(grayscale_images[i])\n",
        "            grayscale_img_array.mean()\n",
        "            axes[1][i].imshow(grayscale_img_array, cmap='gray') # grayscale ì´ë¯¸ì§€ëŠ” cmap='gray' ì„¤ì •\n",
        "            axes[1][i].set_title(f\"Grayscale {grayscale_img_array.mean():.1f}\")  # grayscale í‰ê· ê°’\n",
        "            axes[1][i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# ì‚¬ìš©í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "image_list = ['cars_7.gif', 'flowers_75.png', 'cars_70.gif']  # ì´ë¦„ ì§ì ‘ ì§€ì •\n",
        "image_list = sorted_images[::10][:3]    # 10ê°œì”© ê±´ë„ˆë„ì–´ 3ê°œ ì´ë¯¸ì§€\n",
        "# image_list = [image_folder + '/' + filename for filename in image_list]\n",
        "image_list = [os.path.join(image_folder, filename) for filename in image_list]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "visualize_resized_images(image_list)\n"
      ],
      "metadata": {
        "id": "FBjxVT3HJPJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **ìƒ‰ìƒ(RGB) í‰ê· ê°’ ê¸°ë°˜ ì •ë ¬**\n",
        "<br> íŒŒë€ìƒ‰ í‰ê· ê°’ ê¸°ë°˜ ì •ë ¬"
      ],
      "metadata": {
        "id": "iqVTmt9q4ex7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_color(image_path):\n",
        "    image = Image.open(image_path).resize((50, 50))  # ê³„ì‚° ì†ë„ ê°œì„ \n",
        "    arr = np.array(image)\n",
        "    return arr[:, :, :3].mean(axis=(0, 1))  # RGB í‰ê·   arr[:, :, :3]=[í–‰.ì—´,ë©´]\n",
        "\n",
        "# # Rê°’ ê¸°ì¤€ ì •ë ¬\n",
        "# sorted_images_by_r = sorted(image_files, key=lambda x: get_avg_color(os.path.join(image_folder, x))[0])\n",
        "# # Gê°’ ê¸°ì¤€ ì •ë ¬\n",
        "# sorted_images_by_r = sorted(image_files, key=lambda x: get_avg_color(os.path.join(image_folder, x))[1])\n",
        "# Bê°’ ê¸°ì¤€ ì •ë ¬\n",
        "sorted_images_by_r = sorted(image_files,\n",
        "                            key=lambda x: get_avg_color(os.path.join(image_folder, x))[2],\n",
        "                            reverse=True)\n",
        "\n",
        "# print(sorted_images_by_r[:3])\n",
        "# print(sorted_images[::50])\n",
        "\n",
        "# ì‚¬ìš©í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "image_list = sorted_images[::10][:3]    # 50ê°œì”© ê±´ë„ˆë„ì–´ 3ê°œ ì´ë¯¸ì§€\n",
        "image_list = [image_folder + '/' + filename for filename in image_list]\n",
        "# image_list = [os.path.join(image_folder, filename) for filename in image_list]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "visualize_resized_images(image_list)"
      ],
      "metadata": {
        "id": "GZ1Yy0GC440b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **íŒŒë€ìƒ‰ í‰ê·  ê°’ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬**"
      ],
      "metadata": {
        "id": "VVoZ2wRIUu89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blue_distribution_score_weighted_avg(image_path):\n",
        "    image = Image.open(image_path).resize((50, 50))\n",
        "    arr = np.array(image)\n",
        "    rgb_avg = arr[:, :, :3].mean(axis=(0, 1))\n",
        "    r_avg, g_avg, b_avg = rgb_avg\n",
        "    # ê°„ë‹¨í•˜ê²Œ íŒŒë€ìƒ‰ í‰ê· ì—ì„œ ë‹¤ë¥¸ ìƒ‰ìƒ í‰ê· ì„ ë¹¼ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬\n",
        "    score = b_avg - (r_avg + g_avg) / 2\n",
        "    return score\n",
        "\n",
        "# íŒŒë€ìƒ‰ ë¶„í¬ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
        "sorted_images_by_blue_distribution = sorted(image_files,\n",
        "                                             key=lambda x: get_blue_distribution_score_weighted_avg(os.path.join(image_folder, x)),\n",
        "                                             reverse=True)\n",
        "\n",
        "print(sorted_images_by_blue_distribution[::10])\n",
        "\n",
        "# ì‚¬ìš©í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "image_list = sorted_images_by_blue_distribution[::10][:3]    # 50ê°œì”© ê±´ë„ˆë„ì–´ 3ê°œ ì´ë¯¸ì§€\n",
        "image_list = [os.path.join(image_folder, filename) for filename in image_list]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "visualize_resized_images(image_list)"
      ],
      "metadata": {
        "id": "Z3vId6m_OPDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **íŠ¹ì • ì„ê³„ê°’ ì´ìƒì˜ íŒŒë€ìƒ‰ í”½ì…€ ë¹„ìœ¨ í™œìš©**"
      ],
      "metadata": {
        "id": "kOxP68-EVV6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blue_distribution_score_threshold(image_path):\n",
        "    image = Image.open(image_path).resize((50, 50))\n",
        "    arr = np.array(image)\n",
        "    blue_channel = arr[:, :, 2]  # íŒŒë€ìƒ‰ ì±„ë„ ì¶”ì¶œ\n",
        "    threshold = 200  # íŒŒë€ìƒ‰ìœ¼ë¡œ ê°„ì£¼í•  ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)\n",
        "    blue_pixels_count = np.sum(blue_channel > threshold)\n",
        "    total_pixels = arr.shape[0] * arr.shape[1]\n",
        "    blue_ratio = blue_pixels_count / total_pixels\n",
        "    return blue_ratio\n",
        "\n",
        "\n",
        "# íŒŒë€ìƒ‰ ë¶„í¬ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
        "sorted_images_by_blue_distribution_threshold = sorted(image_files,\n",
        "                                             key=lambda x: get_blue_distribution_score_threshold(os.path.join(image_folder, x)),\n",
        "                                             reverse=True)\n",
        "print(sorted_images_by_blue_distribution_threshold[::50])\n",
        "\n",
        "# ì‚¬ìš©í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
        "image_list = sorted_images_by_blue_distribution_threshold[::10][:3]    # 50ê°œì”© ê±´ë„ˆë„ì–´ 3ê°œ ì´ë¯¸ì§€\n",
        "image_list = [os.path.join(image_folder, filename) for filename in image_list]\n",
        "\n",
        "# í•¨ìˆ˜ í˜¸ì¶œ\n",
        "visualize_resized_images(image_list)"
      ],
      "metadata": {
        "id": "DCCaCy4pVWEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-hpa9WWR5F99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ ì‹¤ìŠµ**\n",
        "- [ì£¼ì˜!] ìˆ˜ì—…ì‹œê°„ì— ì‚¬ìš©í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì •ë ¬í•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤. ì´ë¯¸ì§€ ê°¯ìˆ˜ë¥¼ ì‘ê²Œ í•´ì„œ í…ŒìŠ¤íŠ¸í•˜ê¸°!"
      ],
      "metadata": {
        "id": "A-hkJcHK4fLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â¡ï¸ ì´ë¯¸ì§€ë¥¼ ë°ê¸° ê°’ìœ¼ë¡œ ì •ë ¬í•˜ê¸°\n",
        "def get_avg_brightness(image_path):\n",
        "    \"\"\"ì´ë¯¸ì§€ì˜ í‰ê·  ë°ê¸° ê³„ì‚° (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}\")\n",
        "            return 0\n",
        "\n",
        "        image = Image.open(image_path).convert('L')\n",
        "        arr = np.array(image)\n",
        "        brightness = arr.mean()\n",
        "        return brightness\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ ({os.path.basename(image_path)}): {e}\")\n",
        "        return 0"
      ],
      "metadata": {
        "id": "p0w6KseZikWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iv4p8hnq0z-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# â¡ï¸ ë²„ë¸” ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„\n",
        "def bubble_sort_images(image_path, n):\n",
        "    for i in range(n):\n",
        "        for j in range(0, n - i - 1):\n",
        "            brightness_j = get_avg_brightness(image_path[j])\n",
        "            brightness_next = get_avg_brightness(image_path[j + 1])\n",
        "            if brightness_j > brightness_next:\n",
        "                image_path[j], image_path[j + 1] = image_path[j + 1], image_path[j]\n",
        "    return image_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ë¯¸ì§€ í´ë” ì§€ì •\n",
        "image_folder = 'images'  # ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ í´ë”\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('jpg'))]\n",
        "image_files = image_files[:10]\n",
        "print(image_files)\n",
        "image_path = [os.path.join(image_folder, f) for f in image_files]\n",
        "\n",
        "# ì •ë ¬ ì‹¤í–‰\n",
        "sorted_images_bubble = bubble_sort_images(image_path, len(image_path) )\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\nğŸ“¸ ë°ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì´ë¯¸ì§€ ëª©ë¡:\")\n",
        "for img in sorted_images:\n",
        "    print(img, os.path.basename(img) )\n",
        "    print(f\"{os.path.basename(img)} â†’ ë°ê¸°: {round(get_avg_brightness(img), 2)}\")"
      ],
      "metadata": {
        "id": "U4E1iReMm8W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[ì‹¤ìŠµ]** í€µ ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë°ê¸°ê°’ ì •ë ¬"
      ],
      "metadata": {
        "id": "1bUEU3nGnFD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â¡ï¸ í€µ ì •ë ¬ í•¨ìˆ˜\n",
        "def quick_sort_images(image_path, n):\n",
        "    if n <= 1:\n",
        "        return image_path\n",
        "\n",
        "    pivot = image_path[0]\n",
        "    pivot_brightness = get_avg_brightness(pivot)\n",
        "\n",
        "    less = [img for img in image_path[1:] if get_avg_brightness(img) <= pivot_brightness]\n",
        "    greater = [img for img in image_path[1:] if get_avg_brightness(img) > pivot_brightness]\n",
        "\n",
        "    return quick_sort_images(less, len(less)) + [pivot] + quick_sort_images(greater, len(greater))"
      ],
      "metadata": {
        "id": "_915qe95iVwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â¡ï¸ ì •ë ¬ ì‹¤í–‰\n",
        "sorted_images_quick = quick_sort_images(image_path, len(image_path) )\n",
        "\n",
        "\n",
        "# â¡ï¸ ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\nğŸ“¸ ë°ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì´ë¯¸ì§€ ëª©ë¡:\")\n",
        "for img in sorted_images:\n",
        "    print(f\"{os.path.basename(img)} â†’ ë°ê¸°: {round(get_avg_brightness(img), 2)}\")\n",
        "\n",
        "\n",
        "# â¡ï¸ ë²„ë¸” ì •ë ¬ê³¼ ê²°ê³¼ê°€ ë™ì¼í•œì§€ í™•ì¸\n",
        "print(f\"Sort results {'â­• Match' if sorted_images_bubble == sorted_images_quick else 'âŒ Mismatch'}\")\n"
      ],
      "metadata": {
        "id": "Lxmo2C9uip1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "d0-sIrWa5H1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. AI ì´ë¯¸ì§€ ë°ì´í„° ì •ë ¬**"
      ],
      "metadata": {
        "id": "nXOfqtij5Qw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- ğŸ’¡ **NOTE**\n",
        "    - ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KHIcfXn8RArA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œí•˜ê¸°**\n",
        "- íŒŒì¼ëª…\n",
        "- AI ì´ë¯¸ì§€ ë¶„ë¥˜ íƒœê·¸ëª… (ì˜ˆ: \"Golden Retriever\", \"Mountain Bike\")\n",
        "- Feature Vector (ViT ëª¨ë¸ì˜ ì¶œë ¥ ë²¡í„°)"
      ],
      "metadata": {
        "id": "QVGqlEjQ1zcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš” ì‹œ)\n",
        "!pip install transformers torch torchvision scikit-learn matplotlib pillow --quiet"
      ],
      "metadata": {
        "id": "vBRMdFXO3IGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš” ì‹œ)\n",
        "#!pip install transformers torch pandas pillow --quiet\n",
        "\n",
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import ViTFeatureExtractor, ViTModel, ViTForImageClassification\n",
        "\n",
        "# 3. ëª¨ë¸ ë¡œë“œ\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "model_cls = ViTForImageClassification.from_pretrained(model_name)\n",
        "model_vec = ViTModel.from_pretrained(model_name)\n",
        "\n",
        "model_cls.eval()\n",
        "model_vec.eval()\n",
        "\n",
        "# 4. ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ ì„¤ì •\n",
        "image_folder = \"images\"\n",
        "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# 5. íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜\n",
        "def extract_features(img_path):\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # ë¶„ë¥˜ íƒœê·¸\n",
        "    with torch.no_grad():\n",
        "        outputs_cls = model_cls(**inputs)\n",
        "        logits = outputs_cls.logits\n",
        "        pred_label_id = logits.argmax(-1).item()\n",
        "        label_name = model_cls.config.id2label[pred_label_id]\n",
        "\n",
        "    # feature vector ì¶”ì¶œ\n",
        "    with torch.no_grad():\n",
        "        outputs_vec = model_vec(**inputs)\n",
        "        cls_vector = outputs_vec.last_hidden_state[:, 0, :].squeeze().numpy()  # [CLS] token\n",
        "\n",
        "    return label_name, cls_vector\n",
        "\n",
        "# 6. ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬\n",
        "data = []\n",
        "\n",
        "for fname in image_files:\n",
        "    path = os.path.join(image_folder, fname)\n",
        "    label, vec = extract_features(path)\n",
        "    row = {\n",
        "        \"filename\": fname,\n",
        "        \"label\": label,\n",
        "        **{f\"feat_{i}\": v for i, v in enumerate(vec)}  # feature vector í™•ì¥\n",
        "    }\n",
        "    data.append(row)\n",
        "\n",
        "# 7. pandasë¡œ ì •ë¦¬\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 8. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
        "print(df[['filename', 'label']].head())\n",
        "\n",
        "# 9. CSVë¡œ ì €ì¥\n",
        "df.to_csv(\"image_features_with_labels.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "X6j8ILIF2ADb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ë¶„ë¥˜ê¸°ë°˜ìœ¼ë¡œ ìë™ íƒœê¹… ë° ì •ë ¬**"
      ],
      "metadata": {
        "id": "IC17Qj8X0hu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install transformers torch torchvision matplotlib pillow --quiet\n",
        "\n",
        "\n",
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 3. ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ë¡œë“œ (ì‚¬ì „í•™ìŠµëœ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš©)\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name)\n",
        "\n",
        "# 4. ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜\n",
        "def classify_image(img_path):\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_label = logits.argmax(-1).item()\n",
        "    label_name = model.config.id2label[predicted_label]\n",
        "    return label_name\n",
        "\n",
        "# 5. ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ ì§€ì • ë° íƒœê¹…\n",
        "image_folder = \"images\"  # ì˜ˆ: ë¡œì»¬ ë””ë ‰í„°ë¦¬ ë˜ëŠ” colabì— ì—…ë¡œë“œí•œ í´ë”\n",
        "tagged_images = []\n",
        "\n",
        "for file_name in sorted(os.listdir(image_folder)):\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_path = os.path.join(image_folder, file_name)\n",
        "        tag = classify_image(img_path)\n",
        "        tagged_images.append((file_name, tag))\n",
        "\n",
        "# 6. íƒœê·¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "tagged_images.sort(key=lambda x: x[1])  # ì•ŒíŒŒë²³ ìˆœ ì •ë ¬\n",
        "\n",
        "# 7. ê²°ê³¼ ì‹œê°í™”\n",
        "def display_images_by_tag(tagged_images, image_folder, cols=4):\n",
        "    rows = (len(tagged_images) + cols - 1) // cols\n",
        "    plt.figure(figsize=(15, rows * 3))\n",
        "    for i, (fname, tag) in enumerate(tagged_images):\n",
        "        img = Image.open(os.path.join(image_folder, fname))\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"{tag}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 8. ì¶œë ¥\n",
        "display_images_by_tag(tagged_images, image_folder)"
      ],
      "metadata": {
        "id": "RD0wsz5Sytr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§**\n",
        "- n_clusters = 3  # ì›í•˜ëŠ” í´ëŸ¬ìŠ¤í„° ìˆ˜"
      ],
      "metadata": {
        "id": "chA97PqO0MZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "# !pip install transformers torch torchvision scikit-learn matplotlib pillow --quiet\n",
        "\n",
        "\n",
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from transformers import ViTFeatureExtractor, ViTModel\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 3. ëª¨ë¸ ë° ì „ì²˜ë¦¬ê¸° ë¡œë“œ (ë¶„ë¥˜ìš©ì´ ì•„ë‹Œ feature vectorìš©)\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "model = ViTModel.from_pretrained(model_name)\n",
        "model.eval()  # ì¶”ë¡  ëª¨ë“œ\n",
        "\n",
        "\n",
        "# 4. íŠ¹ì§• ë²¡í„° ì¶”ì¶œ í•¨ìˆ˜\n",
        "def extract_feature_vector(img_path):\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # [CLS] tokenì˜ ì¶œë ¥ ë²¡í„° ì‚¬ìš© (1, hidden_dim)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "    return cls_embedding\n",
        "\n",
        "\n",
        "# 5. ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ì—ì„œ íŠ¹ì§• ì¶”ì¶œ\n",
        "image_folder = \"images\"  # ë³¸ì¸ì˜ ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ ì§€ì •\n",
        "image_vectors = []\n",
        "image_files = []\n",
        "\n",
        "for file_name in sorted(os.listdir(image_folder)):\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        path = os.path.join(image_folder, file_name)\n",
        "        vec = extract_feature_vector(path)\n",
        "        image_vectors.append(vec)\n",
        "        image_files.append(file_name)\n",
        "\n",
        "\n",
        "# 6. KMeans í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰\n",
        "n_clusters = 3  # ì›í•˜ëŠ” í´ëŸ¬ìŠ¤í„° ìˆ˜\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "clusters = kmeans.fit_predict(image_vectors)\n",
        "\n",
        "\n",
        "# 7. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì •ë¦¬\n",
        "clustered_images = list(zip(image_files, clusters))\n",
        "clustered_images.sort(key=lambda x: x[1])  # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ ê¸°ì¤€ ì •ë ¬\n",
        "\n",
        "\n",
        "# 8. ì‹œê°í™” í•¨ìˆ˜\n",
        "def display_clustered_images(clustered_images, image_folder, cols=4):\n",
        "    rows = (len(clustered_images) + cols - 1) // cols\n",
        "    plt.figure(figsize=(15, rows * 3))\n",
        "    for i, (fname, cluster_id) in enumerate(clustered_images):\n",
        "        img = Image.open(os.path.join(image_folder, fname))\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Cluster {cluster_id}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 9. ê²°ê³¼ ì¶œë ¥\n",
        "display_clustered_images(clustered_images, image_folder)"
      ],
      "metadata": {
        "id": "gxis9QjDy--o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}